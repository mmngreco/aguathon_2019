{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, GRU, SimpleRNN, Dropout, Activation, RepeatVector, TimeDistributed\n",
    "from keras.regularizers import l1\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import preprocessing\n",
    "import math\n",
    "\n",
    "# import os\n",
    "# os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"\n",
    "\n",
    "plt.switch_backend('TkAgg')\n",
    "%matplotlib inline\n",
    "\n",
    "# get data\n",
    "fname = \"./datos.csv\"\n",
    "data = pd.read_csv(fname, index_col=0)\n",
    "data.index = data.index.astype(\"datetime64[ns]\")\n",
    "data.sort_index(ascending=True, inplace=True)\n",
    "data_fixed = data.groupby(lambda x: x.weekofyear).transform(lambda x: x.fillna(x.mean()))\n",
    "all_levels = data_fixed.iloc[:, :6].values.astype(\"float64\")\n",
    "names = data_fixed.columns[:6]\n",
    "river_i_list = [0,1,2,3,4,5]\n",
    "river_i_list = [5]\n",
    "\n",
    "np.random.seed(7)\n",
    "\n",
    "# Get current size\n",
    "fig_size = plt.rcParams[\"figure.figsize\"]\n",
    " \n",
    "# Set figure width to 12 and height to 9\n",
    "fig_size[0] = 12\n",
    "fig_size[1] = 9\n",
    "plt.rcParams[\"figure.figsize\"] = fig_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(dataset, train_frac):\n",
    "    train_size = int(len(dataset)*train_frac)\n",
    "    return dataset[:train_size, :], dataset[train_size: ,:]\n",
    "\n",
    "def create_datasets(dataset, look_back=1, look_ahead=1):\n",
    "    data_x, data_y = [], []\n",
    "    for i in range(len(dataset)-look_back-look_ahead+1):\n",
    "        window = dataset[i:(i+look_back), 0]\n",
    "        data_x.append(window)\n",
    "        data_y.append(dataset[i + look_back:i + look_back + look_ahead , 0])\n",
    "    return np.array(data_x), np.array(data_y)\n",
    "\n",
    "def build_seq2seq_model(look_ahead=1):\n",
    "    m = Sequential()\n",
    "    # encoder\n",
    "    m.add(GRU(16, input_shape=(None, 1)))\n",
    "    # repeat for the number of steps out\n",
    "    m.add(RepeatVector(look_ahead))\n",
    "    # decoder\n",
    "    m.add(GRU(8, return_sequences=True))\n",
    "    m.add(GRU(8, return_sequences=True))\n",
    "    # split the output into timesteps\n",
    "    m.add(TimeDistributed(Dense(1)))\n",
    "    m.compile(loss='mse', optimizer='rmsprop')\n",
    "    #m.summary()\n",
    "    return m\n",
    "\n",
    "def reverse_scale(data, mean, std):\n",
    "    for x in np.nditer(data, op_flags=['readwrite']):\n",
    "        x[...] = x*std + mean\n",
    "    return data\n",
    "\n",
    "def calculate_error(train_y, test_y, pred_train, pred_test):\n",
    "    test_score = math.sqrt(mean_squared_error(test_y, pred_test))\n",
    "    train_score = math.sqrt(mean_squared_error(train_y, pred_train))\n",
    "    return train_score, test_score\n",
    "\n",
    "def mean_absolute_percentage(y, y_pred):\n",
    "    return np.mean(np.abs((y - y_pred) / y)) * 100\n",
    "\n",
    "def root_mse(pred_test, test_y):\n",
    "    t = []\n",
    "    for i in range(20):\n",
    "        score = math.sqrt(mean_squared_error(pred_test[:,i,:], test_y[:,i,:]))\n",
    "        t.append(score)\n",
    "        print(i+1, \"  ->  \", score)\n",
    "        \n",
    "    return score\n",
    "\n",
    "def plot_4_errors(pred_test, test_y, er1, er2, er3, er4):\n",
    "    plt.subplot(221)\n",
    "    plt.plot(test_y[:,0,:], label=\"Observed\")\n",
    "    plt.plot(pred_test[:,0,:], color=\"red\", label=\"Predicted, MAPE: \"+ str(round(er1, 5))+\"%\")\n",
    "    plt.title(\"1 step ahead prediction\")\n",
    "    plt.ylabel(\"River Level\")\n",
    "    plt.legend(loc=1, fontsize = 8, framealpha=0.8)\n",
    "    \n",
    "    plt.subplot(222)\n",
    "    plt.plot(pred_test[:,3,:], color=\"red\", label=\"Predicted, MAPE: \"+ str(round(er2, 5))+\"%\")\n",
    "    plt.plot(test_y[:,3,:], label=\"Observed\")\n",
    "    plt.title(\"4 step ahead prediction\")\n",
    "    plt.legend(loc=1, fontsize = 8, framealpha=0.8)\n",
    "\n",
    "    plt.subplot(223)\n",
    "    plt.plot(pred_test[:,7,:], color=\"red\", label=\"Predicted, MAPE: \"+ str(round(er3, 5))+\"%\")\n",
    "    plt.plot(test_y[:,7,:], label=\"Observed\")\n",
    "    plt.title(\"8 step ahead prediction\")\n",
    "    plt.legend(loc=1, fontsize = 8, framealpha=0.8)\n",
    "\n",
    "    plt.subplot(224)\n",
    "    plt.plot(pred_test[:,15,:], color=\"red\", label=\"Predicted, MAPE: \"+ str(round(er4, 5))+\"%\")\n",
    "    plt.plot(test_y[:,15,:], label=\"Observed\")\n",
    "    plt.title(\"16 step ahead prediction\")\n",
    "    plt.legend(loc=1, fontsize = 8, framealpha=0.8)\n",
    "\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_everything(look_back, look_ahead, river_level, split, epochs, batch_size):\n",
    "    river = river_level\n",
    "    # river = all_levels[all_levels['riverstation_id'] == riverstation_id]['level'].values\n",
    "    \n",
    "    river_mean, river_std = river.mean(), river.std()\n",
    "\n",
    "    river = preprocessing.scale(river).reshape(len(river), 1)\n",
    "\n",
    "    # split data into train and test subsets\n",
    "    train, test = train_test_split(river, split)\n",
    "    train_x, train_y = create_datasets(train, look_back, look_ahead)\n",
    "    test_x, test_y = create_datasets(test, look_back, look_ahead)\n",
    "\n",
    "    # reshape the data to match Keras LSTM gate input [samples, time steps, features]\n",
    "    train_x = np.reshape(train_x, (train_x.shape[0], train_x.shape[1], 1))\n",
    "    train_y = np.reshape(train_y, (train_y.shape[0], train_y.shape[1], 1))\n",
    "\n",
    "    test_x = np.reshape(test_x, (test_x.shape[0], test_x.shape[1], 1))\n",
    "    test_y = np.reshape(test_y, (test_y.shape[0], test_y.shape[1], 1))\n",
    "\n",
    "    model = build_seq2seq_model(look_ahead)\n",
    "\n",
    "    model.fit(train_x, \n",
    "              train_y, \n",
    "              epochs=epochs, \n",
    "              batch_size=batch_size, \n",
    "              verbose=2,\n",
    "              validation_split = 0.1,\n",
    "              callbacks = [\n",
    "                EarlyStopping(monitor='val_loss', min_delta=0.001, patience=3, verbose=2, mode='auto')\n",
    "              ]\n",
    "             )\n",
    "\n",
    "    pred_train = model.predict(train_x)\n",
    "    pred_test = model.predict(test_x)\n",
    "\n",
    "    pred_train = reverse_scale(pred_train, river_mean, river_std)\n",
    "    pred_test = reverse_scale(pred_test, river_mean, river_std)\n",
    "    test_y = reverse_scale(test_y, river_mean, river_std)\n",
    "    train_y = reverse_scale(train_y, river_mean, river_std)\n",
    "    \n",
    "    errors = []\n",
    "    for i in range(20):\n",
    "        errors.append(mean_absolute_percentage(test_y[:,i,:], pred_test[:,i,:]))\n",
    "        \n",
    "    plot_4_errors(pred_test, test_y, errors[0], errors[3], errors[7], errors[15])\n",
    "    # root_mse(pred_test, test_y)\n",
    "    \n",
    "    errors = []\n",
    "    for i in range(20):\n",
    "        errors.append(mean_absolute_percentage(test_y[:,i,:], pred_test[:,i,:]))\n",
    "        \n",
    "    return errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mmngreco/miniconda3/envs/river/lib/python3.6/site-packages/ipykernel_launcher.py:16: UserWarning: The `input_dim` and `input_length` arguments in recurrent layers are deprecated. Use `input_shape` instead.\n",
      "  app.launch_new_instance()\n",
      "/Users/mmngreco/miniconda3/envs/river/lib/python3.6/site-packages/ipykernel_launcher.py:16: UserWarning: Update your `GRU` call to the Keras 2 API: `GRU(16, input_shape=(None, 1))`\n",
      "  app.launch_new_instance()\n",
      "/Users/mmngreco/miniconda3/envs/river/lib/python3.6/site-packages/ipykernel_launcher.py:30: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 68940 samples, validate on 7661 samples\n",
      "Epoch 1/50\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "for i in river_i_list:\n",
    "    err = do_everything(look_back=64,\n",
    "                        look_ahead=20,\n",
    "                        river_level=all_levels[:, i],\n",
    "                        split=0.8,\n",
    "                        epochs=50,\n",
    "                        batch_size=10)\n",
    "    scores.append(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
